{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n# Overview \n\n[Optimal Approach for Image Recognition using Deep Convolutional Architecture](https://arxiv.org/abs/1904.11187)\n\n# Abstract \n\n> The article mainly focuses on the state-of-art deep learning models and\nvarious real world applications specific training methods. Selecting optimal architecture for specific problem is a challenging task, at a closing\nstage of the article we proposed optimal approach to deep convolutional\narchitecture for the application of image recognition.\n\n# Introduction \n\n> In any artificial intelligence problem we require two main things. First, we need\nto identify and extract right set of features that represent the problem. Second,\nwe need to have an algorithm that takes these extracted features and provides\npredicted outputs.\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"# 2. Literaturre Review \n\n## 2.1 LeNet \n\n> LeNet consist of 5 convolution layers for feature extraction and object detection.\n\nJust adding a quick example about how to implement Lenet in 9 lines of Keras \n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from keras import Sequential, Model \nfrom keras.layers import Conv2D, AveragePooling2D, Flatten, Dense \n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(32,32,1)))\nmodel.add(AveragePooling2D())\n\nmodel.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\nmodel.add(AveragePooling2D())\n\nmodel.add(Flatten())\n\nmodel.add(Dense(units=120, activation='relu'))\n\nmodel.add(Dense(units=84, activation='relu'))\n\nmodel.add(Dense(units=10, activation = 'softmax'))\n\nmodel.summary()","execution_count":2,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_3 (Conv2D)            (None, 30, 30, 6)         60        \n_________________________________________________________________\naverage_pooling2d_3 (Average (None, 15, 15, 6)         0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 13, 13, 16)        880       \n_________________________________________________________________\naverage_pooling2d_4 (Average (None, 6, 6, 16)          0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 576)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 120)               69240     \n_________________________________________________________________\ndense_5 (Dense)              (None, 84)                10164     \n_________________________________________________________________\ndense_6 (Dense)              (None, 10)                850       \n=================================================================\nTotal params: 81,194\nTrainable params: 81,194\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"\nRelevant aspects \n\n- Input Tensor is defined as `input_shape=(32,32,1)` so a `32x32x1` Tensor is a `32x32` Mono Image \n- Total number of params is only 81k (the order of magnitude for todays CNN is $10^7$ Params)\n"},{"metadata":{},"cell_type":"markdown","source":"Work in progress "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}
